<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.7.2" />
<title>acd.scores.score_funcs API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>acd.scores.score_funcs</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import torch
import numpy as np
import torch.nn.functional as F
import torch.nn as nn
import sys
from ..util.conv2dnp import conv2dnp
import copy
from .cd import cd, cd_text
from tqdm import tqdm


def gradient_times_input_scores(im, ind, model, device=&#39;cuda&#39;):
    ind = torch.LongTensor([np.int(ind)]).to(device)
    if im.grad is not None:
        im.grad.data.zero_()
    pred = model(im)
    crit = nn.NLLLoss()
    loss = crit(pred, ind)
    loss.backward()
    res = im.grad * im
    return res.data.cpu().numpy()[0, 0]




def ig_scores_2d(model, im_torch, num_classes=10, im_size=28, sweep_dim=1, ind=None, device=&#39;cuda&#39;):
    &#39;&#39;&#39;Compute IG scores
    &#39;&#39;&#39;
    
    for p in model.parameters():
        if p.grad is not None:
            p.grad.data.zero_()
            
    # What class to produce explanations for
    output = np.zeros((im_size * im_size // (sweep_dim * sweep_dim), num_classes))
    
    if ind is None:
        ind = range(num_classes)
    for class_to_explain in ind:
        #         _, class_to_explain = model(im_torch).max(1); class_to_explain = class_to_explain.data[0]

        M = 100
        criterion = torch.nn.L1Loss(size_average=False)
        mult_grid = np.array(range(M)) / (M - 1)

        baseline = torch.zeros(im_torch.shape).to(device)

        input_vecs = torch.empty((M, baseline.shape[1],  baseline.shape[2], baseline.shape[3]), 
                                  dtype=torch.float32,
                                  device=device, requires_grad=False)
        &#39;&#39;&#39;
        input_vecs = torch.Tensor(M, baseline.size(1), 
                                  baseline.size(2), baseline.size(3)).to(device)
        input_vecs.requires_grad = True
        &#39;&#39;&#39;
        for i, prop in enumerate(mult_grid):
            input_vecs[i].data = baseline + (prop * (im_torch.to(device) - baseline))
        input_vecs.requires_grad=True

#         input_vecs = input_vecs

        out = F.softmax(model(input_vecs))[:, class_to_explain]
        loss = criterion(out, torch.zeros(M).to(device))
        loss.backward()

        imps = input_vecs.grad.mean(0).data.cpu() * (im_torch.data.cpu() - baseline.cpu())
        ig_scores = imps.sum(1)

        # Sanity check: this should be small-ish
        #         print((out[-1] - out[0]).data[0] - ig_scores.sum())
        scores = ig_scores.cpu().numpy().reshape((1, im_size, im_size, 1))
        kernel = np.ones(shape=(sweep_dim, sweep_dim, 1, 1))
        scores_convd = conv2dnp(scores, kernel, stride=(sweep_dim, sweep_dim))
        output[:, class_to_explain] = scores_convd.flatten()
    return output


def ig_scores_1d(batch, model, inputs, device=&#39;cuda&#39;):
    for p in model.parameters():
        if p.grad is not None:
            p.grad.data.zero_()
    M = 1000
    criterion = torch.nn.L1Loss(size_average=False)
    mult_grid = np.array(range(M)) / (M - 1)
    word_vecs = model.embed(batch.text).data
    baseline_text = copy.deepcopy(batch.text)
    baseline_text.data[:, :] = inputs.vocab.stoi[&#39;.&#39;]
    baseline = model.embed(baseline_text).data
    input_vecs = torch.Tensor(baseline.size(0), M, baseline.size(2)).to(device)
    for i, prop in enumerate(mult_grid):
        input_vecs[:, i, :] = baseline + (prop * (word_vecs - baseline)).to(device)

    input_vecs = input_vecs

    hidden = (torch.zeros(1, M, model.hidden_dim).to(device),
              torch.zeros(1, M, model.hidden_dim).to(device))
    lstm_out, hidden = model.lstm(input_vecs, hidden)
    logits = F.softmax(model.hidden_to_label(lstm_out[-1]))[:, 0]
    loss = criterion(logits, torch.zeros(M).to(device))
    loss.backward()
    imps = input_vecs.grad.mean(1).data * (word_vecs[:, 0] - baseline[:, 0])
    zero_pred = logits[0]
    scores = imps.sum(1)
    #     for i in range(sent_len):
    #         print(ig_scores[i], text_orig[i])
    # Sanity check: this should be small-ish
    #     print((logits[-1] - zero_pred) - ig_scores.sum())
    return scores.cpu().numpy()


# return scores (higher is better)
def get_scores_1d(batch, model, method, label, only_one, score_orig, text_orig, subtract=False, device=&#39;cuda&#39;):
    # calculate scores
    if method == &#39;cd&#39;:
        if only_one:
            num_words = batch.text.data.cpu().numpy().shape[0]
            scores = np.expand_dims(cd_text(batch, model, start=0, stop=num_words), axis=0)
        else:
            starts, stops = tiles_to_cd(batch)
            batch.text.data = torch.LongTensor(text_orig).to(device)
            scores = np.array([cd_text(batch, model, start=starts[i], stop=stops[i])
                               for i in range(len(starts))])
    else:
        scores = model(batch).data.cpu().numpy()
        if method == &#39;occlusion&#39; and not only_one:
            scores = score_orig - scores

    # get score for other class
    if subtract:
        return scores[:, label] - scores[:, int(1 - label)]
    else:
        return scores[:, label]


# return scores (higher is better)
def get_scores_2d(model, method, ims, im_torch=None, pred_ims=None, model_type=&#39;mnist&#39;, device=&#39;cuda&#39;):
    scores = []
    if method == &#39;cd&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(cd(im_torch, model, np.expand_dims(ims[i], 0), model_type, device=device)[0].data.cpu().numpy())
        scores = np.squeeze(np.array(scores))
    elif method == &#39;build_up&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(pred_ims(model, ims[i])[0])
        scores = np.squeeze(np.array(scores))
    elif method == &#39;occlusion&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(pred_ims(model, ims[i])[0])
        scores = -1 * np.squeeze(np.array(scores))
    if scores.ndim == 1:
        scores = scores.reshape(1, -1)
    return scores


# converts build up tiles into indices for cd
# Cd requires batch of [start, stop) with unigrams working
# build up tiles are of the form [0, 0, 12, 35, 0, 0]
# return a list of starts and indices
def tiles_to_cd(batch):
    starts, stops = [], []
    tiles = batch.text.data.cpu().numpy()
    L = tiles.shape[0]
    for c in range(tiles.shape[1]):
        text = tiles[:, c]
        start = 0
        stop = L - 1
        while text[start] == 0:
            start += 1
        while text[stop] == 0:
            stop -= 1
        starts.append(start)
        stops.append(stop)
    return starts, stops</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="acd.scores.score_funcs.get_scores_1d"><code class="name flex">
<span>def <span class="ident">get_scores_1d</span></span>(<span>batch, model, method, label, only_one, score_orig, text_orig, subtract=False, device='cuda')</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_scores_1d(batch, model, method, label, only_one, score_orig, text_orig, subtract=False, device=&#39;cuda&#39;):
    # calculate scores
    if method == &#39;cd&#39;:
        if only_one:
            num_words = batch.text.data.cpu().numpy().shape[0]
            scores = np.expand_dims(cd_text(batch, model, start=0, stop=num_words), axis=0)
        else:
            starts, stops = tiles_to_cd(batch)
            batch.text.data = torch.LongTensor(text_orig).to(device)
            scores = np.array([cd_text(batch, model, start=starts[i], stop=stops[i])
                               for i in range(len(starts))])
    else:
        scores = model(batch).data.cpu().numpy()
        if method == &#39;occlusion&#39; and not only_one:
            scores = score_orig - scores

    # get score for other class
    if subtract:
        return scores[:, label] - scores[:, int(1 - label)]
    else:
        return scores[:, label]</code></pre>
</details>
</dd>
<dt id="acd.scores.score_funcs.get_scores_2d"><code class="name flex">
<span>def <span class="ident">get_scores_2d</span></span>(<span>model, method, ims, im_torch=None, pred_ims=None, model_type='mnist', device='cuda')</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_scores_2d(model, method, ims, im_torch=None, pred_ims=None, model_type=&#39;mnist&#39;, device=&#39;cuda&#39;):
    scores = []
    if method == &#39;cd&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(cd(im_torch, model, np.expand_dims(ims[i], 0), model_type, device=device)[0].data.cpu().numpy())
        scores = np.squeeze(np.array(scores))
    elif method == &#39;build_up&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(pred_ims(model, ims[i])[0])
        scores = np.squeeze(np.array(scores))
    elif method == &#39;occlusion&#39;:
        for i in tqdm(range(ims.shape[0])):  # can use tqdm here, need to use batches
            scores.append(pred_ims(model, ims[i])[0])
        scores = -1 * np.squeeze(np.array(scores))
    if scores.ndim == 1:
        scores = scores.reshape(1, -1)
    return scores</code></pre>
</details>
</dd>
<dt id="acd.scores.score_funcs.gradient_times_input_scores"><code class="name flex">
<span>def <span class="ident">gradient_times_input_scores</span></span>(<span>im, ind, model, device='cuda')</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gradient_times_input_scores(im, ind, model, device=&#39;cuda&#39;):
    ind = torch.LongTensor([np.int(ind)]).to(device)
    if im.grad is not None:
        im.grad.data.zero_()
    pred = model(im)
    crit = nn.NLLLoss()
    loss = crit(pred, ind)
    loss.backward()
    res = im.grad * im
    return res.data.cpu().numpy()[0, 0]</code></pre>
</details>
</dd>
<dt id="acd.scores.score_funcs.ig_scores_1d"><code class="name flex">
<span>def <span class="ident">ig_scores_1d</span></span>(<span>batch, model, inputs, device='cuda')</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ig_scores_1d(batch, model, inputs, device=&#39;cuda&#39;):
    for p in model.parameters():
        if p.grad is not None:
            p.grad.data.zero_()
    M = 1000
    criterion = torch.nn.L1Loss(size_average=False)
    mult_grid = np.array(range(M)) / (M - 1)
    word_vecs = model.embed(batch.text).data
    baseline_text = copy.deepcopy(batch.text)
    baseline_text.data[:, :] = inputs.vocab.stoi[&#39;.&#39;]
    baseline = model.embed(baseline_text).data
    input_vecs = torch.Tensor(baseline.size(0), M, baseline.size(2)).to(device)
    for i, prop in enumerate(mult_grid):
        input_vecs[:, i, :] = baseline + (prop * (word_vecs - baseline)).to(device)

    input_vecs = input_vecs

    hidden = (torch.zeros(1, M, model.hidden_dim).to(device),
              torch.zeros(1, M, model.hidden_dim).to(device))
    lstm_out, hidden = model.lstm(input_vecs, hidden)
    logits = F.softmax(model.hidden_to_label(lstm_out[-1]))[:, 0]
    loss = criterion(logits, torch.zeros(M).to(device))
    loss.backward()
    imps = input_vecs.grad.mean(1).data * (word_vecs[:, 0] - baseline[:, 0])
    zero_pred = logits[0]
    scores = imps.sum(1)
    #     for i in range(sent_len):
    #         print(ig_scores[i], text_orig[i])
    # Sanity check: this should be small-ish
    #     print((logits[-1] - zero_pred) - ig_scores.sum())
    return scores.cpu().numpy()</code></pre>
</details>
</dd>
<dt id="acd.scores.score_funcs.ig_scores_2d"><code class="name flex">
<span>def <span class="ident">ig_scores_2d</span></span>(<span>model, im_torch, num_classes=10, im_size=28, sweep_dim=1, ind=None, device='cuda')</span>
</code></dt>
<dd>
<section class="desc"><p>Compute IG scores</p></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def ig_scores_2d(model, im_torch, num_classes=10, im_size=28, sweep_dim=1, ind=None, device=&#39;cuda&#39;):
    &#39;&#39;&#39;Compute IG scores
    &#39;&#39;&#39;
    
    for p in model.parameters():
        if p.grad is not None:
            p.grad.data.zero_()
            
    # What class to produce explanations for
    output = np.zeros((im_size * im_size // (sweep_dim * sweep_dim), num_classes))
    
    if ind is None:
        ind = range(num_classes)
    for class_to_explain in ind:
        #         _, class_to_explain = model(im_torch).max(1); class_to_explain = class_to_explain.data[0]

        M = 100
        criterion = torch.nn.L1Loss(size_average=False)
        mult_grid = np.array(range(M)) / (M - 1)

        baseline = torch.zeros(im_torch.shape).to(device)

        input_vecs = torch.empty((M, baseline.shape[1],  baseline.shape[2], baseline.shape[3]), 
                                  dtype=torch.float32,
                                  device=device, requires_grad=False)
        &#39;&#39;&#39;
        input_vecs = torch.Tensor(M, baseline.size(1), 
                                  baseline.size(2), baseline.size(3)).to(device)
        input_vecs.requires_grad = True
        &#39;&#39;&#39;
        for i, prop in enumerate(mult_grid):
            input_vecs[i].data = baseline + (prop * (im_torch.to(device) - baseline))
        input_vecs.requires_grad=True

#         input_vecs = input_vecs

        out = F.softmax(model(input_vecs))[:, class_to_explain]
        loss = criterion(out, torch.zeros(M).to(device))
        loss.backward()

        imps = input_vecs.grad.mean(0).data.cpu() * (im_torch.data.cpu() - baseline.cpu())
        ig_scores = imps.sum(1)

        # Sanity check: this should be small-ish
        #         print((out[-1] - out[0]).data[0] - ig_scores.sum())
        scores = ig_scores.cpu().numpy().reshape((1, im_size, im_size, 1))
        kernel = np.ones(shape=(sweep_dim, sweep_dim, 1, 1))
        scores_convd = conv2dnp(scores, kernel, stride=(sweep_dim, sweep_dim))
        output[:, class_to_explain] = scores_convd.flatten()
    return output</code></pre>
</details>
</dd>
<dt id="acd.scores.score_funcs.tiles_to_cd"><code class="name flex">
<span>def <span class="ident">tiles_to_cd</span></span>(<span>batch)</span>
</code></dt>
<dd>
<section class="desc"></section>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tiles_to_cd(batch):
    starts, stops = [], []
    tiles = batch.text.data.cpu().numpy()
    L = tiles.shape[0]
    for c in range(tiles.shape[1]):
        text = tiles[:, c]
        start = 0
        stop = L - 1
        while text[start] == 0:
            start += 1
        while text[stop] == 0:
            stop -= 1
        starts.append(start)
        stops.append(stop)
    return starts, stops</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="acd.scores" href="index.html">acd.scores</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="acd.scores.score_funcs.get_scores_1d" href="#acd.scores.score_funcs.get_scores_1d">get_scores_1d</a></code></li>
<li><code><a title="acd.scores.score_funcs.get_scores_2d" href="#acd.scores.score_funcs.get_scores_2d">get_scores_2d</a></code></li>
<li><code><a title="acd.scores.score_funcs.gradient_times_input_scores" href="#acd.scores.score_funcs.gradient_times_input_scores">gradient_times_input_scores</a></code></li>
<li><code><a title="acd.scores.score_funcs.ig_scores_1d" href="#acd.scores.score_funcs.ig_scores_1d">ig_scores_1d</a></code></li>
<li><code><a title="acd.scores.score_funcs.ig_scores_2d" href="#acd.scores.score_funcs.ig_scores_2d">ig_scores_2d</a></code></li>
<li><code><a title="acd.scores.score_funcs.tiles_to_cd" href="#acd.scores.score_funcs.tiles_to_cd">tiles_to_cd</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.7.2</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>